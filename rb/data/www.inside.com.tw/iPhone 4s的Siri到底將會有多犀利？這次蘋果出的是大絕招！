

在上週，iPhone 4S正式亮相，大部份媒體都關注在硬體規格上的改變以及失望，但從蘋果過去的硬體升級經驗來說，不管是從iPhone 初代到iPhone 3G以及iPhone 3GS，不只是外觀上沒有大幅度改變，硬體的部份也都像是限定升級，出現如iPhone 4S般的結果，其實是很不令人意外的，實際上以目前媒體的評測結果，速度比前代iPhone 4大幅增加的狀況下，耗電量不變，而相機的效果亦大幅提升，這些都還是很驚人的。
硬體是其次，重點其實在Siri，在官方的iPhone 4S片長約5分鐘的宣傳影片中，Siri的介紹占了1/5強的時間，可見其重要性一般。那麼到底Siri的重要性在哪？為什麼他可能是改變遊戲規則的重量型服務呢？我昨天睡不著無聊在 Quora 上翻看文章，找到了這篇「Why is Siri important?」，相當的令人瞠目結舌的答案，相當推薦將原文看過一遍，並把裡頭的連結全部看一次，由於這個領域對我來說相當的陌生，如果有理解錯誤，歡迎高手留言指正：）
這不是傳統的語音辨識或命令系統
有很多人會把多年前的拉麵機或者是近來Google 的語音命令拿來跟Siri相提並論，再說一次，這些不是同一個層次的東西，他是人工智慧、自動學習(continual learning)加上情境感知系統(contextual awareness system)的綜合體，Siri可以被視為真正的「綜效」（定義是：兩個或更多事物並放在一起，產生新的結果，中文在Wikipedia被解釋為 1加 1大於 2的結果），幾個沒有新意的東西加在一起，產生Siri這個前所未聞的產品。
電腦科學研究者們的聖杯之一，就是有一天，可以創造出一個裝置，它可以像人類般的進行有智慧的對話。我們可能有過一些很好笑語音辨識系統經驗，但直到近年來的科技不斷演進，Siri就是它的副產品。
Siri的歷史以及DARPA
DARPA，中文可以被翻為美國國防部高級研究規劃局（這名字聽起來就很威），這個單位最著名的發明就是網際網路，而這個單位也促成了Siri的發明，DARPA資助史丹佛研究學院（SRI）的國際人工智慧中心的相關計劃，而這個單位獨立出來後則成為了Siri Inc.。
最初的Siri是1960年代被美國國防部作為「在複雜情境下的電腦智慧能力發展」計劃，在多年的研究後，史丹佛研究學院在透過一堆超強人才的協助下，開創了一條創新之路。這個研究計劃一共被資助了長達40年以上，而蘋果買的就是這個研究成果，其中包含了一狗票頂尖大學的研究團隊結果，內容包括了對話以及自然語言理解、機器學習等等一堆高深技術。
對的時間與對的科技
早年的語音辨識以及人工智慧失敗已經有許多的突破點，主要因為電腦的運算能力以及作業系統的工作能力有大幅成長，摩爾定律加上網際網路以及蘋果的硬體能力，配上40年的研究成果，組合出了Siri今日的結果，Siri主要專注在此一科技的3大重點：
對話介面 (Conversational Interface)
個人情境感知 (Personal Context Awareness)
服務委派 (Service Delegation)
第4代電腦介面
Siri將成為第4代，也許也是最重要的與裝置互動的方式。鍵盤、滑鼠與手勢仍然會常見，不會立刻消失。但人類最有效的溝通方式就是透過說話，最大的障礙就在於，如果把一個簡單的問題轉換成裝置理解的方式，並有對應的回答，古老的一個蘿蔔一個坑的問答方式不會立刻不見，但是想像如果你對機器問個簡單問題，就好像是對圖書館管理員或者是朋友般自然，這將會非常、非常的強大。
裝置小需要更聰明
螢幕永遠是不夠大的，跟搜尋引擎不一樣的是，Siri更專注在行動使用的情境模組，比如說地點、時間、個人歷史以及限定的情境，使其能夠發揮強大的智慧助手功能。小螢幕、行動情境以及有限的手機頻寬，使得聲音成為最好的問題溝通介面，提供適當的細節並給予適當的問題。
在行動環境下，你沒很多時間翻閱一堆頁面來找連結、在介面裡頭切換或者是打開應用程式來找到答案，一個簡單的語音問題解決使用者20個手動工作，這就是Siri的威力。
完成工作是終極目標
傳統的輸入系統，我們可能要花很多時間搜尋以及步驟才會找到結果，而且要全部做完才能找到結果，透過Siri，他會幫你直接略過中間所有步驟直接到結果。

幫你把事情作完
- 垂直以及水平搜尋
- 即時同時結合多重資訊來源
- 即時以動態標準編輯資訊
- 介接終端，比如說購買票券等等
理解你說什麼 - 對話意向
- 地點情境 Location context
- 時間情境 Time context
- 任務情境 Task context
- 對話情境 Dialog context
了解你- 學習個人化資訊並執行行動
- 你的朋友/家人有誰
- 你住哪
- 你的年齡
- 你喜歡什麼

透過雲端要產出可接受的結果，這要包含以下的東西：
地點感知
時間感知
任務感知
語意資料
雲端API連接
任務以及主控模組
對話介面
文字轉換為意向
語音轉化為文字
文字轉化為語音
對話流程
個人資訊以及人口統計資訊
社交圖譜 (Social Graph)
設交資料 (Social Data)
當然蘋果的A5 雙核心處理器處理的許多前端的工作，但主要的感知資料都在雲端，並準備用來處理語音辨識完的資訊。
實際使用
在蘋果的發表會上，Siri的操作是「按鈕然後問」，但實際上他能夠長時間放著被問問題，不需要按鈕啟動，但要被優化還要等到強大的噪音過慮以及啟動辨識技術被開發出來，同時間Siri也可以被與Bluetooth 4耳機最佳化，可想而知的是，這樣就能夠連續的語音辨識以及偵測問題。
未來，Siri將可以長時間的處於啟動狀態，並視情境來確定是否回答問題（這不就是霹靂車的夥計嗎？），這將使得這個介面更像是與朋友互動。
新的經濟生態系，雲端上的APIs
當理解人們如何使用Siri，接下來就不難知道應用程式將會有多麼熱門，而某些商業模式將會慢慢失去效用。或者未來我們不稱之為應用程式，而是提供給雲端使用的連結API，Siri將創造出新的一種生態圈，就好像iTunes app store創造出來的效果一樣。

 
未來，透過API，Siri將可以取得這些API所提供的資訊。未來蘋果最大的挑戰就是，怎麼樣從網路上找到資料，整合回到Siri並提供給使用者有意義的東西，這將會一片廣大的新商機，但蘋果是否會開放API仍在未定之天，但是透過某種的審核機制，來確保資料的品質，看起來很像是蘋果一貫的作風。你可以想像在合適API的提供下，你可以問下面的問題：
我的帳戶還有多少錢？
下一班307公車離我這裡還多遠？
聽（朋友）fOx 正在聽的歌。
鋼鐵擂台在美麗華是不是有演？幾點？幫我訂兩張成人票。
對面的房子是不是有出租？平均一坪價格多少錢？
給我宮保雞丁的食譜，幫我把食材丟到備忘錄去，當我經過頂好時提醒我買。
這只是開始
與裝置互動的革命，現在才開始，我們已知道的所有介面，包含鍵盤、滑鼠等進入App以及網路的方式都不會消失。而Siri對於裝置互動會不會有巨大影響，也尚不得而知。
但這會從iPhone 4S開始，接下來會是iPad 3，接著是Apple TV，再加上Bluetooth 4以及Bluetooth低耗能(BLE)，將會大大改變互動關係，裝上BLE的門，透過Siri就可以說「Siri，幫我開門」或者是「當Amber來的時候，把前門鎖打開」。
NFC？也許會被直接略過.....（可以參考原作者的另一篇文章）
還有待觀察
當然，所有的科技以及研究都還在開展中，也有一大堆問題等著被解決，也許5年後我們就可以真的看見這類型科技所帶來的衝擊，這將是一場鬧劇？還是終極的改變我們與裝置互動的方式？時間會證明一切。
TechCrunch的MG Siegler，在他實測iPhone 4S之後的心得是：
我們一直在科幻影集與電影中看到人們對電腦說話，就好像跟人類說話般自然，而電腦也理解他們。那個未來就是現在。
We’ve all seen the science fiction television shows and films where people talk to their computers like human beings and the computer understands them. That future is now.

